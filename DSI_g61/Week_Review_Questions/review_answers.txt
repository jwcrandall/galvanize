1. **Gradient Descent: What is an objective function? Give an example of a cost function to minimize and a cost function to maximize.**

  An objective function is the function that you are trying to minimize or maximize. A function to minimize would be a loss/cost/error function and a function to maximize would be a likelihood function.

2. **Gradient Descent : instantiate the dataset**

  ```python
  X = np.array([[-9, -7, -1],
                [ 6, -5, -2],
                [-7, -1,  8],
                [ 3, -1,  6]])

  y = np.array([[-26],
                [-10],
                [ 15],
                [ 19]])
  ```
  * **Compute the gradient for the objective function with respect to the parameters.**
  <p>
  (1/N) Σ (y - xβ)<sup>2</sup> = (1/N) Σ (y - (x<sub>1</sub>β<sub>1</sub> + x<sub>2</sub>β<sub>2</sub> + x<sub>3</sub>β<sub>3</sub>))<sup>2</sup>
  <p>_(parameters are β<sub>1</sub>, β<sub>2</sub>, β<sub>3</sub>)_

    gradient = -2/N Σ (y - (x<sub>1</sub>β<sub>1</sub> + x<sub>2</sub>β<sub>2</sub> + x<sub>3</sub>β<sub>3</sub>)) (x<sub>1</sub> hat{β}<sub>1</sub> + x<sub>2</sub> hat{β}<sub>2</sub> + x<sub>3</sub> hat{β}<sub>3</sub>})

    in code:
    ```python
    grad_func = -(2/N)*X.T.dot((y - X.dot(β))
    ```  
  * **Evaluate the gradient at β<sub>1</sub> = β<sub>2</sub> = β<sub>3</sub> = 1**

    <p>enter in a column vector for betas and plug into gradient equation
    ```python
    In [76]: betas = np.ones(shape = (3, 1))
    In [77]: grad = -(2/X.shape[0])*(y - X.dot(betas)).T.dot(X)
    In [78]: grad  
    Out[78]: array([[  22.5,  -41. , -106.5]])
    ```
  * **Compute a parameter update for a learning rate of α = .0001.**

    <p> multiply the gradient (transposed so that beta remains a column vector) by the learning rate and subtract from old parameters
    ```python
    In [79]: betas_new = betas - .0001*grad

    In [80]: betas_new
    Out[80]:
    array([[ 0.99775],
           [ 1.0041 ],
           [ 1.01065]])

    # extra - if you perform this iteration enough times, you get the correct betas back out - like so
    def grad_desc(X, y, alpha = .0001, \
                  betas = np.ones(shape = (3, 1)), \
                  n = 10000):
        for _ in range(n):
            grad = -(2/X.shape[0])*X.T.dot((y - X.dot(betas))
            betas = betas - alpha*grad
        return betas

    # this was the loss function for a simple linear regression
    # test X.dot(betas) to reproduce y  
    In [90]: grad_desc(X, y)
    Out[90]:
    array([[ 1.],
           [ 2.],
           [ 3.]])         
    ```

3. **Describe the three types of gradient descent and discuss advantages and disadvantages of each. What are the main hyperparameters to tune in gradient descent?**

    <p>**Batch gradient descent** - where we perform a gradient update considering the entire dataset at once. (this is what we just did)
    <p>**Stochastic gradient descent** - perform a gradient update one datapoint at a time.
    <p>**Mini-batch gradient descent** - the 'happy medium', perform gradient updates on subsets of the data

    <p>**hyperparameters:** learning rate, batch size.

4. **Name some other optimization algorithms/variants on gradient descent and give a brief overview of how they work.**

    <p>**Adaptive Learning Rate** - algorithms that decay the learning rate (see slide - many variations)
    <p>**Momentum** - apply a fraction of the previous step's update to the current update
    <p>**Newton's Method** - adjusts parameters based on the second derivative (acceleration) instead of the first derivative.

5. **You're trying to make model that will predict the female gold medal winner in the high jump in the next Olympics.  You have results and data for 1000 high-jumpers in the past.  You're using four features: `jumper_height`, `jumper_weight`, `best_jump_height`, and `fastest_100m_time` as features and your model performs ... just ok during cross-validation. Then it hits you: you also have `maximum_squat_weight` for all the jumpers, why don't you use that as a feature too?  Using this additional feature (5 total now) during cross-validation, however, you get widely varying estimates of model performance.  What do you think is going on?**  

   An indication of an overfit model is that its predictions for test cases will vary widely when it's trained on different subsets of the training data.  Increased model complexity enables overfitting.  So in this case, whatever information was provided by adding that fifth feature was offset by the higher variance induced by the increased complexity of the model.  Besides model complexity, another reason for the higher variance is that there is much less data per feature "volume" in the 5 dimensional feature space than there was in the 4 dimensional feature space.  And so there is less information telling your model how it should fit.

   **As a bonus, how many data points would you need with 5 features to have the same sample density as your model had with 4 features?**

   N<sub>1</sub><sup>(1/d1)</sup> ~ N<sub>2</sub><sup>(1/d2)</sup>   
   1000<sup>(1/4)</sup> ~ N<sub>2</sub><sup>(1/5)</sup>  
   N<sub>2</sub> ~ 1000<sup>(5/4)</sup>  
   N<sub>2</sub> ~ 5600 points

6. **Decision tree questions:**  
  * **Describe, step-by-step, how a decision tree is built.**  
    In machine learning, decision trees are a series of sequential splitting rules on the features of data that attempt to partition the corresponding labels into homogeneous groups.  Decisions, or splits, are made at nodes on the existing data on one feature and a **splitting_value** in the range of that feature, and data and their corresponding labels flow "to the left" or "to the right" depending if their value for that feature is equal or not (categorical feature) or <= or > (continuously valued) to the **splitting_value.**  As there are multiple features and multiple values for each feature, there needs to be a way to determine what split at that decision node is "best."  This is done by trying to maximize the information gain associated with that particular split by evaluating the reduction in entropy (classification) or variance (regression) of the label associated with splitting on that feature and its **splitting_value**.  
    A decision tree would be made step-by-step in the following way:  

    ```
      at an existing node:  
         if:  
           the data in that node have all the same label y  
           or  
           all possible splits have been made on X  
           then stop splitting  
         else:  
           determine which feature in X and what value in that feature provide the most information gain  
           split the data "to the left" and "to the right" which makes new left and right nodes  
           go through this process again for each node
     ```  

  * **Describe how a binary split is made at a node in the case of:**  
  In both classification and regression you'd like to maximize the information gain associated with that split.
  * **classification**  
    In classification, the goal is to maximally reduce entropy (or gini impurity).  In the case of entropy the equation is:  
    IG = H(P) - (#C1/#P)xH(C1) - (#C2/#P)xH(C2)  
    where  
    IG is the information gain  
    P is the parent node  
    #P is the number of datapoints in P  
    C1 and C2 are the child nodes  
    #C1, #C2 are the number of datpoints in C1 and C2  
    H(X) is the entropy of the parent or child nodes (see class notes)

  * **regression**  
    Here the IG is calculated similar to that in classification, though variance the same measure of disorder in each node instead of entropy or gini impurity.

  * **You decide to use a Decision Tree on the Olympic high jumper problem and you end up with a model that does very well on the training data but predicts poorly in cross-validation.  What can you do?**  
  If the building process is not constrained the Decision Tree will fit the training data as closely as possible.  Most likely, it will be overfit.  Post-pruning the tree should reduce the variance.  

7. **What are the two things that make a random forest "random"?**
    <p>* Each tree is fit on a sample bootstrapped from the original sample. (Random sample of data). 
    <p>* Each split made in each tree only considers a subset of features.

8. **What problem from bagging is solved by using a random forest? Hint: what type of algorithm is a decision tree split?**

    Decision tree splits (chosen by information gain) are greedy, and so a highly predictive feature will be the first split every time in bagging, despite the slight altering of the sample. Thus, your trees created by bagging will be highly correlated and easy to overfit. By presenting only a random subset of features, you can de-correlate your trees, which allows them to generalize well to new data.

9. **You are a data scientist at a subscription company, and you decide to use a random forest model for predicting churn. The model works well, but your boss wants some insight into what factors contribute to customer churn. What can you tell him/her?**

    You could look at feature importances, which tell you the proportion of splits made with each column. This roughly translates to how much predictive power each feature has, but does not tell you direction or effect size.
    You could also look at partial dependency plots to look at predictive power as a function of the values of each feature (usually, only look at the most predictive ones).

10. **Compare and contrast random forests and boosted trees with regards to:**  
  * The data that each tree in the ensemble is built on.  
  *Random forest: each tree is built on a bootstrapped sample of the training data.  
  Boosting: after the first tree each tree is built on either re-weighted data (Adaboost) or on the residuals (gradient boosting) of the previous tree.*
  * How is the quality of a split on a given feature and its value is evaluated.  
  *In both cases the goal is still to maximize information gain: the maximum reduction in variance (regression) or entropy/gini impurity (classification)*
  * The general depth of each tree.  
  *Random forest: each tree is grown pretty deep.  
  Boosting: usually the trees are decision stumps (only 1 or 2 splits)*
  * The bias-variance trade-off associated with each tree in the ensemble.  
    *Random forest:  being deep and potentially overfit, each tree will tend to have low bias but high variance.  
    Boosting: being shallow and potentially underfit, each tree will tend to have high bias but low variance.*
  * How the ensemble can achieve a low-bias, low-variance model.  
    *Random forest: by taking the average or majority vote of many overfit learners that tend to have low bias and high variance, the result is an ensemble that has much lower variance but slightly higher bias than any individual tree in the ensemble.  
    Boosting: by taking the end result of a number of weak rules of thumb, where each rule of thumb is a high bias, low variance model, the bias of the ensemble is greatly reduced while slightly increasing the variance.*

11. **Compare and contrast Adaboost and gradient boosting.**  
    In both cases weak learners are built on the training result of the prior learner.  However, they differ in what the training data are.  In gradient boosting the training data are the residuals from the prior learner, while in Adaboost the training data are the original training data re-weighted by their residuals.

12. **Describe the elastic net regularization parameter. Explain the two hyperparameters.**

   The elastic net regularization parameter lets you specify how much L1 and L2 regularization to apply to the cost function during training.  The first hyperparameter - **alpha** or **lambda** - can be any positive real value. It specifies the magnitude of the penalty on the coefficients. The second hyperparameter, the **l1_ratio**, is a number between 0 and 1. It specifies what fractional amount of the total regularization should be attributed to the L1 penalty, with the remainder attributed to the L2 penalty.  

13. **Describe the hyperparameter C associated with SVMs, and how different values of C affect bias and variance of your model.**

   The hyperparameter C controls the "looseness" or width of the margin. A smaller value of C leads to a wider margin while a larger value leads to a smaller margin. Small values of C use a larger number of points to compute the decision boundary, and thus lead to higher bias but lower variance models. Large values of C use a narrow margin, which gives you a lower bias but higher variance model.