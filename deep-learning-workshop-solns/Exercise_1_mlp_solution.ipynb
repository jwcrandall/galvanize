{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1:  Multilayer perceptron on MNIST dataset\n",
    "\n",
    "Build a 2-hidden layer fully connected neural network (a.k.a multilayer perceptron) with TensorFlow to classify digits in the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "Adapted from Github User [aymericdamienhtt](https://github.com/aymericdamien) with use governed by the [MIT license](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set:  (55000, 784)\n",
      "Shape of the test set:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the training set: \", mnist.train.images.shape)\n",
    "print(\"Shape of the test set: \", mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of one image is:  (784,)\n",
      "The maximum pixel intensity in the selected image is:  0.996078\n",
      "The minimum pixel intensity in the selected image is:  0.0\n",
      "The one-hot encoded label for this image is: \n",
      "[ 0   1   2   3   4   5   6   7   8   9]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "\n",
      "Made into a 28 x 28 pixel image the image looks like:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb611c4828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at one image\n",
    "img = 0 # feel free to modify\n",
    "print(\"The shape of one image is: \", mnist.train.images[0].shape)\n",
    "print(\"The maximum pixel intensity in the selected image is: \", mnist.train.images[0].max())\n",
    "print(\"The minimum pixel intensity in the selected image is: \", mnist.train.images[0].min())\n",
    "print(\"The one-hot encoded label for this image is: \")\n",
    "print(\"[ 0   1   2   3   4   5   6   7   8   9]\")\n",
    "print(mnist.train.labels[img])\n",
    "print(\"\\nMade into a 28 x 28 pixel image the image looks like:\")\n",
    "plt.imshow(mnist.train.images[img].reshape(28, 28), cmap = 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model and network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1  # tuneable parameter adusting how much weights are updated\n",
    "num_epochs = 500     # how many times will we pass through the whole dataset during training\n",
    "batch_size = 128     # how many rows of data during training should a weight update be based on\n",
    "display_epoch = 100   # after how many epochs would we like to see training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons \n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the tensors (constants, placeholders, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensor placeholders for the input and output\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, shape = (None, num_input))\n",
    "Y = tf.placeholder(tf.float32, shape = (None, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make variable tensors for the weights and biases\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal(shape=(num_input, n_hidden_1))),\n",
    "    'h2': tf.Variable(tf.random_normal(shape=(n_hidden_1, n_hidden_2))),\n",
    "    'out': tf.Variable(tf.random_normal(shape=(n_hidden_2, num_classes)))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal(shape=(n_hidden_1,))),\n",
    "    'b2': tf.Variable(tf.random_normal(shape=(n_hidden_2,))),\n",
    "    'out': tf.Variable(tf.random_normal(shape=(num_classes,)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define, using operations, the feed-forward calculation of layer values\n",
    "def feed_forward(x):\n",
    "    # First hidden fully connected layer\n",
    "    z1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    a1 = tf.nn.sigmoid(z1)\n",
    "    # Second hidden fully connected layer\n",
    "    z2 = tf.add(tf.matmul(a1, weights['h2']), biases['b2'])\n",
    "    a2 = tf.nn.sigmoid(z2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out = tf.add(tf.matmul(a2, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the feed_forward operation, get the predictions\n",
    "logits = feed_forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss, see the [softmax](https://en.wikipedia.org/wiki/Softmax_function) and [cross_entropy](https://en.wikipedia.org/wiki/Cross_entropy) definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss operation and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer operation\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom accuracy operation\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can finally initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a session and train and test\n",
    "Useful tensorflow fuctions:\n",
    "make minibatches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Minibatch Loss= 11.5589, Training Accuracy= 0.102\n",
      "Epoch 100, Minibatch Loss= 2.1384, Training Accuracy= 0.555\n",
      "Epoch 200, Minibatch Loss= 1.2614, Training Accuracy= 0.656\n",
      "Epoch 300, Minibatch Loss= 0.8842, Training Accuracy= 0.734\n",
      "Epoch 400, Minibatch Loss= 1.3279, Training Accuracy= 0.680\n",
      "Epoch 500, Minibatch Loss= 0.9876, Training Accuracy= 0.773\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7549\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # get a minibatch to train on\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # Run the training operation to update the weights, use a feed_dict to use batch_x and batch_y\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        \n",
    "        # display output if desired\n",
    "        if epoch % display_epoch == 0 or epoch == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            # You can run multiple operations using a list\n",
    "            # as above, use a feed dictionary for batch_x, batch_y\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Epoch \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Run the accuracy operations for the MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
